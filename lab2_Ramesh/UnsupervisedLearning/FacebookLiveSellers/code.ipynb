{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Clustering Facebook Live Sellers**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is taken from Prashant Banerjee's submission on [kaggle.com](https://www.kaggle.com/prashant111/k-means-clustering-with-python/notebook).\n",
                "\n",
                "You are encouraged to go to the link above and check out the full code. In this lab, you will do the necessary steps to explore the data and prepare it for sklearn algorithms."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**About the data set**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Live selling is becoming increasingly popular in Asian countries. Small vendors can now reach a wider audience and connect with many customers. \n",
                "\n",
                "K-Means clustering is used to find intrinsic groups within the unlabelled dataset and draw inferences from them. In this kernel, you will implement K-Means clustering to find intrinsic groups within the dataset that display the same status_type behaviour."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np # linear algebra\n",
                "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
                "import matplotlib.pyplot as plt # for data visualization\n",
                "import seaborn as sns # for statistical data visualization\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Acquire data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003estatus_id\u003c/th\u003e\n      \u003cth\u003estatus_type\u003c/th\u003e\n      \u003cth\u003estatus_published\u003c/th\u003e\n      \u003cth\u003enum_reactions\u003c/th\u003e\n      \u003cth\u003enum_comments\u003c/th\u003e\n      \u003cth\u003enum_shares\u003c/th\u003e\n      \u003cth\u003enum_likes\u003c/th\u003e\n      \u003cth\u003enum_loves\u003c/th\u003e\n      \u003cth\u003enum_wows\u003c/th\u003e\n      \u003cth\u003enum_hahas\u003c/th\u003e\n      \u003cth\u003enum_sads\u003c/th\u003e\n      \u003cth\u003enum_angrys\u003c/th\u003e\n      \u003cth\u003eColumn1\u003c/th\u003e\n      \u003cth\u003eColumn2\u003c/th\u003e\n      \u003cth\u003eColumn3\u003c/th\u003e\n      \u003cth\u003eColumn4\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1649696485147474\u003c/td\u003e\n      \u003ctd\u003evideo\u003c/td\u003e\n      \u003ctd\u003e4/22/2018 6:00\u003c/td\u003e\n      \u003ctd\u003e529\u003c/td\u003e\n      \u003ctd\u003e512\u003c/td\u003e\n      \u003ctd\u003e262\u003c/td\u003e\n      \u003ctd\u003e432\u003c/td\u003e\n      \u003ctd\u003e92\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1649426988507757\u003c/td\u003e\n      \u003ctd\u003ephoto\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 22:45\u003c/td\u003e\n      \u003ctd\u003e150\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e150\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1648730588577397\u003c/td\u003e\n      \u003ctd\u003evideo\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 6:17\u003c/td\u003e\n      \u003ctd\u003e227\u003c/td\u003e\n      \u003ctd\u003e236\u003c/td\u003e\n      \u003ctd\u003e57\u003c/td\u003e\n      \u003ctd\u003e204\u003c/td\u003e\n      \u003ctd\u003e21\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1648576705259452\u003c/td\u003e\n      \u003ctd\u003ephoto\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 2:29\u003c/td\u003e\n      \u003ctd\u003e111\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e111\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1645700502213739\u003c/td\u003e\n      \u003ctd\u003ephoto\u003c/td\u003e\n      \u003ctd\u003e4/18/2018 3:22\u003c/td\u003e\n      \u003ctd\u003e213\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e204\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n      \u003ctd\u003eNaN\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "                          status_id status_type status_published  \\\n0  246675545449582_1649696485147474       video   4/22/2018 6:00   \n1  246675545449582_1649426988507757       photo  4/21/2018 22:45   \n2  246675545449582_1648730588577397       video   4/21/2018 6:17   \n3  246675545449582_1648576705259452       photo   4/21/2018 2:29   \n4  246675545449582_1645700502213739       photo   4/18/2018 3:22   \n\n   num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n0            529           512         262        432         92         3   \n1            150             0           0        150          0         0   \n2            227           236          57        204         21         1   \n3            111             0           0        111          0         0   \n4            213             0           0        204          9         0   \n\n   num_hahas  num_sads  num_angrys  Column1  Column2  Column3  Column4  \n0          1         1           0      NaN      NaN      NaN      NaN  \n1          0         0           0      NaN      NaN      NaN      NaN  \n2          1         0           0      NaN      NaN      NaN      NaN  \n3          0         0           0      NaN      NaN      NaN      NaN  \n4          0         0           0      NaN      NaN      NaN      NaN  "
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv('UnsupervisedLearning/FacebookLiveSellers/Live.csv')\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of the data frame\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inspect data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect the shape of the data frame\n",
                "df.shape()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to get information about null values in the data frame\n",
                "df.info()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clean data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop the four redundant columns in the data set\n",
                "df.drop(['Column1', 'Column2', 'Column3', 'Column4'], \n",
                "axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7050 entries, 0 to 7049\nData columns (total 12 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   status_id         7050 non-null   object\n 1   status_type       7050 non-null   object\n 2   status_published  7050 non-null   object\n 3   num_reactions     7050 non-null   int64 \n 4   num_comments      7050 non-null   int64 \n 5   num_shares        7050 non-null   int64 \n 6   num_likes         7050 non-null   int64 \n 7   num_loves         7050 non-null   int64 \n 8   num_wows          7050 non-null   int64 \n 9   num_hahas         7050 non-null   int64 \n 10  num_sads          7050 non-null   int64 \n 11  num_angrys        7050 non-null   int64 \ndtypes: int64(9), object(3)\nmemory usage: 661.1+ KB\n"
                }
            ],
            "source": [
                "# Check the summary again \n",
                "# to see if there are no redundant columns remaining\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect statistical information about the data set\n",
                "df.describe()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that there are 3 categorical variables in the dataset. We will explore them one by one"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['246675545449582_1649696485147474',\n       '246675545449582_1649426988507757',\n       '246675545449582_1648730588577397', ...,\n       '1050855161656896_1060126464063099',\n       '1050855161656896_1058663487542730',\n       '1050855161656896_1050858841656528'], dtype=object)"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# View the labels in the variable\n",
                "\n",
                "df['status_id'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "6997"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# View how many different types of variables are there\n",
                "\n",
                "len(df['status_id'].unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to view the labels in the variable status_published\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: write code to view how many different types of variables \n",
                "# there are in status_published\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to view the labels in the variable status_type\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: write code to view how many different types of variables \n",
                "# there are in status_type\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the above inspection, we realize that there are 6997 unique labels in the status_id variable and 6913 unique labels in the status_published variable. \n",
                "\n",
                "The total number of instances in the dataset is 7050, which means that these two variables are approximately unique identifiers for each of the instances. Thus these are not variables that we can use, and we should drop them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to drop status_id and status_published\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\u003cclass 'pandas.core.frame.DataFrame'\u003e\nRangeIndex: 7050 entries, 0 to 7049\nData columns (total 12 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   status_id         7050 non-null   object\n 1   status_type       7050 non-null   object\n 2   status_published  7050 non-null   object\n 3   num_reactions     7050 non-null   int64 \n 4   num_comments      7050 non-null   int64 \n 5   num_shares        7050 non-null   int64 \n 6   num_likes         7050 non-null   int64 \n 7   num_loves         7050 non-null   int64 \n 8   num_wows          7050 non-null   int64 \n 9   num_hahas         7050 non-null   int64 \n 10  num_sads          7050 non-null   int64 \n 11  num_angrys        7050 non-null   int64 \ndtypes: int64(9), object(3)\nmemory usage: 661.1+ KB\n"
                }
            ],
            "source": [
                "# View a summary of the data set again\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect the first five rows of the data frame\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Converting**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There is 1 non-numeric column status_type in the dataset. We will convert it into integer equivalents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Split the data set into X and y\n",
                "\n",
                "X = df\n",
                "\n",
                "y = df['status_type']\n",
                "\n",
                "le = LabelEncoder()\n",
                "\n",
                "X['status_type'] = le.fit_transform(X['status_type'])\n",
                "\n",
                "y = le.transform(y)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Inspect X "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003estatus_id\u003c/th\u003e\n      \u003cth\u003estatus_type\u003c/th\u003e\n      \u003cth\u003estatus_published\u003c/th\u003e\n      \u003cth\u003enum_reactions\u003c/th\u003e\n      \u003cth\u003enum_comments\u003c/th\u003e\n      \u003cth\u003enum_shares\u003c/th\u003e\n      \u003cth\u003enum_likes\u003c/th\u003e\n      \u003cth\u003enum_loves\u003c/th\u003e\n      \u003cth\u003enum_wows\u003c/th\u003e\n      \u003cth\u003enum_hahas\u003c/th\u003e\n      \u003cth\u003enum_sads\u003c/th\u003e\n      \u003cth\u003enum_angrys\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1649696485147474\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e4/22/2018 6:00\u003c/td\u003e\n      \u003ctd\u003e529\u003c/td\u003e\n      \u003ctd\u003e512\u003c/td\u003e\n      \u003ctd\u003e262\u003c/td\u003e\n      \u003ctd\u003e432\u003c/td\u003e\n      \u003ctd\u003e92\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1649426988507757\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 22:45\u003c/td\u003e\n      \u003ctd\u003e150\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e150\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1648730588577397\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 6:17\u003c/td\u003e\n      \u003ctd\u003e227\u003c/td\u003e\n      \u003ctd\u003e236\u003c/td\u003e\n      \u003ctd\u003e57\u003c/td\u003e\n      \u003ctd\u003e204\u003c/td\u003e\n      \u003ctd\u003e21\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1648576705259452\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4/21/2018 2:29\u003c/td\u003e\n      \u003ctd\u003e111\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e111\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e246675545449582_1645700502213739\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4/18/2018 3:22\u003c/td\u003e\n      \u003ctd\u003e213\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e204\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "                          status_id  status_type status_published  \\\n0  246675545449582_1649696485147474            3   4/22/2018 6:00   \n1  246675545449582_1649426988507757            1  4/21/2018 22:45   \n2  246675545449582_1648730588577397            3   4/21/2018 6:17   \n3  246675545449582_1648576705259452            1   4/21/2018 2:29   \n4  246675545449582_1645700502213739            1   4/18/2018 3:22   \n\n   num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n0            529           512         262        432         92         3   \n1            150             0           0        150          0         0   \n2            227           236          57        204         21         1   \n3            111             0           0        111          0         0   \n4            213             0           0        204          9         0   \n\n   num_hahas  num_sads  num_angrys  \n0          1         1           0  \n1          0         0           0  \n2          1         0           0  \n3          0         0           0  \n4          0         0           0  "
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Feature Scaling**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "could not convert string to float: '4/22/2018 6:00'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m\u003ccell line: 7\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      5\u001b[0m ms \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m----\u003e 7\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39m[cols])\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--\u003e 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--\u003e 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:453\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--\u003e 453\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    462\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--\u003e 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--\u003e 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/generic.py:2072\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m\u003e\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-\u003e 2072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '4/22/2018 6:00'"
                    ]
                }
            ],
            "source": [
                "# Like in lab 1, use the MinMax scaler to scale values for better accuracy.\n",
                "\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "cols = X.columns\n",
                "ms = MinMaxScaler()\n",
                "\n",
                "X = ms.fit_transform(X)\n",
                "X = pd.DataFrame(X, columns=[cols])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Earn Your Wings"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implement a K-Means Clustering algorithm on the cleaned data set. Use the elbow method to find the right value of k to use.\n",
                "Add comments in your code to explain each step that you take in your implementation."
            ]
        }
    ]
}
